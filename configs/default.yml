model:
    arch: unet
data:
    dataset: larynx
    train_split: train
    val_split: val
    img_cols: 640
    img_rows: 480
    path: None
training:
    train_iters: 5000
    batch_size: 32
    val_interval: 25
    n_workers: 32
    print_interval: 10
    optimizer:
        name: "adam"
        lr: 8.0e-4
        weight_decay: 5.0e-3
    loss:
        name: "cross_entropy"
        reduce: "mean"
        weight: [0.05, 1.0, 1.0]
    lr_schedule:
        name: "cosine_annealing"
        T_max: 700
    augmentations:
        gamma: 0.25
        hue: 0.25
        brightness: 0.20
        saturation: 0.25
        contrast: 0.25
        hflip: 0.5
        translate: [50, 50]
        rotate: 30
    resume: None
